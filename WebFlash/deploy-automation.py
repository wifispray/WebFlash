#!/usr/bin/env python3
"""
Complete Deployment Automation for GitHub Pages
===============================================

This script handles the complete automation for GitHub Pages deployment:
1. Scans firmware directory for .bin files
2. Updates manifest.json with relative URLs
3. Creates individual manifest files for ESP Web Tools
4. Generates GitHub Pages compatible URLs
5. Validates all files and URLs

Usage:
  python3 deploy-automation.py              # Full automation for GitHub Pages
  python3 deploy-automation.py --local      # Local development with localhost URLs
  python3 deploy-automation.py --validate   # Validate existing deployment
"""

import json
import os
import sys
import argparse
from pathlib import Path
from datetime import datetime
import subprocess
import re

class GitHubPagesAutomation:
    def __init__(self, local_mode: bool = False):
        self.local_mode = local_mode
        self.firmware_dir = Path("firmware")
        self.manifest_path = Path("manifest.json")
        self.base_url = "http://localhost:5000/" if local_mode else ""
        
    def log(self, message: str):
        """Log message with timestamp."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {message}")
    
    def extract_metadata_from_path(self, file_path: Path) -> dict:
        """Extract metadata from Model/Variant directory structure and filename."""
        parts = file_path.parts
        
        # Expected structure: firmware/{Model}/{Variant}/{filename}
        if len(parts) < 4:
            return None
        
        model = parts[-3]        # Model name (e.g., "Sense360-MS")
        variant = parts[-2]      # Variant name (e.g., "Standard")
        filename = file_path.name
        
        # Parse filename: {Model}-{Variant}-[sensor-addon-]v{Version}-{Channel}.bin
        # Handle both standard and sensor-specific variants
        expected_prefix = f"{model}-{variant}-"
        if not filename.startswith(expected_prefix):
            return None
            
        # Extract everything after the model-variant prefix
        name_part = filename[len(expected_prefix):]
        if name_part.endswith('.bin'):
            name_part = name_part[:-4]
        elif name_part.endswith('.md'):
            name_part = name_part[:-3]
        
        # Check if this is a sensor-specific variant
        sensor_addon = None
        if name_part.startswith('sen55-hlk2450-v'):
            sensor_addon = 'sen55-hlk2450'
            name_part = name_part[len('sen55-hlk2450-v'):]  # Remove sensor addon prefix
        elif name_part.startswith('v'):
            name_part = name_part[1:]  # Remove 'v' prefix
        else:
            return None
        
        # Split by hyphens to get version-channel
        parts = name_part.split('-')
        if len(parts) < 2:
            return None
        
        version = parts[0]  # Version (e.g., "1.0.0")
        channel = parts[1]  # Channel (e.g., "stable")
        
        return {
            'model': model,
            'variant': variant,
            'sensor_addon': sensor_addon,
            'version': version,
            'channel': channel
        }
    
    def get_chip_family_mapping(self, chip_family: str) -> str:
        """Map chip family to ESP Web Tools format."""
        mapping = {
            'ESP32': 'ESP32',
            'ESP32S2': 'ESP32-S2',
            'ESP32S3': 'ESP32-S3',
            'ESP32C3': 'ESP32-C3',
            'ESP32C6': 'ESP32-C6',
            'ESP32H2': 'ESP32-H2'
        }
        return mapping.get(chip_family, chip_family)
    
    def get_firmware_metadata_from_release_notes(self, model: str, variant: str, version: str, channel: str, sensor_addon: str = None) -> dict:
        """Get firmware metadata from release notes file."""
        # Create release notes filename (ensure version has 'v' prefix)
        version_with_v = version if version.startswith('v') else f"v{version}"
        if sensor_addon:
            release_notes_filename = f"{model}-{variant}-{sensor_addon}-{version_with_v}-{channel}.md"
        else:
            release_notes_filename = f"{model}-{variant}-{version_with_v}-{channel}.md"
        # Look for release notes in the Model/Variant directory
        release_notes_path = self.firmware_dir / model / variant / release_notes_filename
        
        # Default metadata
        metadata = {
            'description': f'{channel.title()} firmware release for {model} {variant} devices',
            'model': model,
            'variant': variant,
            'builtin_sensors': ['Temperature', 'Humidity'],
            'addon_sensors': [],
            'version': version,
            'channel': channel,
            'features': [],
            'hardware_requirements': [],
            'known_issues': [],
            'changelog': []
        }
        
        if not release_notes_path.exists():
            self.log(f"‚ö†Ô∏è  No release notes found for {release_notes_filename}, using defaults")
            return metadata
        
        try:
            with open(release_notes_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extract release description
            description_match = re.search(r'## Release Description\s*\n(.*?)(?=\n##|\n$)', content, re.DOTALL)
            if description_match:
                metadata['description'] = description_match.group(1).strip()
            
            # Extract device information fields
            device_info_match = re.search(r'## Device Information\s*\n(.*?)(?=\n##|\n$)', content, re.DOTALL)
            if device_info_match:
                device_info = device_info_match.group(1).strip()
                
                # Parse individual fields
                model_match = re.search(r'[*\-\s]*Model[*\s]*:\s*(.+)', device_info)
                if model_match:
                    metadata['model'] = model_match.group(1).strip()
                
                variant_match = re.search(r'[*\-\s]*Variant[*\s]*:\s*(.+)', device_info)
                if variant_match:
                    metadata['variant'] = variant_match.group(1).strip()
                
                builtin_match = re.search(r'[*\-\s]*Built-in Sensors[*\s]*:\s*(.+)', device_info)
                if builtin_match:
                    sensors = [s.strip() for s in builtin_match.group(1).split(',')]
                    metadata['builtin_sensors'] = sensors
                
                addon_match = re.search(r'[*\-\s]*Addon Sensors[*\s]*:\s*(.+)', device_info)
                if addon_match:
                    addon_text = addon_match.group(1).strip()
                    if addon_text.lower() != 'none':
                        metadata['addon_sensors'] = [s.strip() for s in addon_text.split(',')]
                    else:
                        metadata['addon_sensors'] = []
                
                # Extract chip family for compatibility
                chip_match = re.search(r'[*\-\s]*Chip Family[*\s]*:\s*(.+)', device_info)
                if chip_match:
                    metadata['chip_family'] = chip_match.group(1).strip()
                
                # Extract device type for compatibility
                device_type_match = re.search(r'[*\-\s]*Device Type[*\s]*:\s*(.+)', device_info)
                if device_type_match:
                    metadata['device_type'] = device_type_match.group(1).strip()
                
                # Extract release date from Release Date field
                release_date_match = re.search(r'[*\-\s]*Release Date[*\s]*:\s*(.+)', device_info)
                if release_date_match:
                    metadata['release_date'] = release_date_match.group(1).strip()
            
            # Extract features
            features_match = re.search(r'## Features\s*\n(.*?)(?=\n##|\n$)', content, re.DOTALL)
            if features_match:
                features_text = features_match.group(1).strip()
                metadata['features'] = [line.strip('- ').strip() for line in features_text.split('\n') if line.strip().startswith('-')]
            
            # Extract hardware requirements
            hardware_match = re.search(r'## Hardware Requirements\s*\n(.*?)(?=\n##|\n$)', content, re.DOTALL)
            if hardware_match:
                hardware_text = hardware_match.group(1).strip()
                metadata['hardware_requirements'] = [line.strip('- ').strip() for line in hardware_text.split('\n') if line.strip().startswith('-')]
            
            # Extract known issues
            issues_match = re.search(r'## Known Issues\s*\n(.*?)(?=\n##|\n$)', content, re.DOTALL)
            if issues_match:
                issues_text = issues_match.group(1).strip()
                metadata['known_issues'] = [line.strip('- ').strip() for line in issues_text.split('\n') if line.strip().startswith('-')]
            
            # Extract changelog
            changelog_match = re.search(r'## Changelog\s*\n(.*?)(?=\n##|\n$)', content, re.DOTALL)
            if changelog_match:
                changelog_text = changelog_match.group(1).strip()
                metadata['changelog'] = [line.strip('- ').strip() for line in changelog_text.split('\n') if line.strip().startswith('-')]
            
            self.log(f"üìã Loaded release notes for {release_notes_filename}")
            return metadata
            
        except Exception as e:
            self.log(f"‚ö†Ô∏è  Error reading release notes {release_notes_filename}: {e}")
            return metadata
    
    def clean_orphaned_manifests(self) -> bool:
        """Clean up all existing firmware-*.json files to ensure clean state."""
        try:
            # Find all existing firmware manifest files with multiple patterns
            manifest_files = []
            for pattern in ['firmware-*.json', 'firmware*.json']:
                manifest_files.extend(list(Path('.').glob(pattern)))
            
            # Remove duplicates
            manifest_files = list(set(manifest_files))
            
            if manifest_files:
                self.log(f"üßπ Cleaning up {len(manifest_files)} existing manifest files...")
                cleanup_success = True
                for manifest_file in manifest_files:
                    try:
                        if manifest_file.exists():
                            manifest_file.unlink()
                            self.log(f"  ‚úì Removed {manifest_file}")
                        else:
                            self.log(f"  ‚ÑπÔ∏è  {manifest_file} already removed")
                    except Exception as e:
                        self.log(f"  ‚úó Failed to remove {manifest_file}: {e}")
                        cleanup_success = False
                
                # Verify cleanup worked
                remaining_files = list(Path('.').glob('firmware-*.json'))
                if remaining_files:
                    self.log(f"  ‚ö†Ô∏è  {len(remaining_files)} files still remain:")
                    for remaining_file in remaining_files:
                        self.log(f"    - {remaining_file}")
                        # Force remove if still exists
                        try:
                            remaining_file.unlink()
                            self.log(f"    ‚úì Force removed {remaining_file}")
                        except Exception as e:
                            self.log(f"    ‚úó Force removal failed: {e}")
                            cleanup_success = False
                
                if not cleanup_success:
                    return False
            else:
                self.log("üßπ No existing manifest files to clean up")
            
            # Double-check cleanup was successful
            final_check = list(Path('.').glob('firmware-*.json'))
            if final_check:
                self.log(f"ERROR: {len(final_check)} manifest files still exist after cleanup!")
                for remaining in final_check:
                    self.log(f"  - {remaining}")
                return False
            
            self.log("‚úÖ Cleanup verified: All firmware-*.json files removed")
            return True
            
        except Exception as e:
            self.log(f"ERROR: Failed to clean up orphaned manifests: {e}")
            return False
    
    def get_build_date(self, file_path: Path, release_metadata: dict = None) -> str:
        """Get build date from release notes, git commit, or file modification time."""
        # First priority: Release Date from .md file
        if release_metadata and 'release_date' in release_metadata:
            release_date = release_metadata['release_date']
            self.log(f"  üìÖ Using release date from .md file: {release_date}")
            return release_date
        
        try:
            # Second priority: git commit date for this file
            result = subprocess.run(
                ['git', 'log', '-1', '--format=%cI', str(file_path)],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0 and result.stdout.strip():
                git_date = result.stdout.strip()
                self.log(f"  üìÖ Using git commit date: {git_date}")
                return git_date
            
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
            # Git not available or no git history for this file
            pass
        
        # Last resort: file modification time
        file_date = datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
        self.log(f"  üìÖ Using file modification date: {file_date}")
        return file_date
    
    def scan_firmware_directory(self) -> list:
        """Scan firmware directory and create builds list."""
        builds = []
        
        if not self.firmware_dir.exists():
            self.log(f"ERROR: Firmware directory {self.firmware_dir} does not exist")
            return builds
            
        for bin_file in self.firmware_dir.rglob("*.bin"):
            metadata = self.extract_metadata_from_path(bin_file)
            
            if metadata:
                # Create relative path for GitHub Pages
                relative_path = str(bin_file.relative_to(Path('.')))
                
                # Get release notes metadata
                release_metadata = self.get_firmware_metadata_from_release_notes(
                    metadata['model'], 
                    metadata['variant'], 
                    metadata['version'], 
                    metadata['channel'],
                    metadata.get('sensor_addon')
                )
                
                # Create variant display name
                variant_display = metadata['variant']
                if metadata.get('sensor_addon'):
                    variant_display = f"{metadata['variant']}-{metadata['sensor_addon']}"
                
                build = {
                    "model": metadata['model'],
                    "variant": variant_display,
                    "device_type": release_metadata.get('device_type', metadata['model']),
                    "version": metadata['version'],
                    "channel": metadata['channel'],
                    "description": release_metadata['description'],
                    "chipFamily": self.get_chip_family_mapping(release_metadata.get('chip_family', 'ESP32-S3')),
                    "builtin_sensors": release_metadata.get('builtin_sensors', []),
                    "addon_sensors": release_metadata.get('addon_sensors', []),
                    "sensor_addon": metadata.get('sensor_addon'),
                    "parts": [{
                        "path": relative_path,
                        "offset": 0
                    }],
                    "build_date": self.get_build_date(bin_file, release_metadata),
                    "file_size": bin_file.stat().st_size,
                    "improv": True,
                    "features": release_metadata['features'][:5] if release_metadata['features'] else [],  # Limit to first 5 features
                    "hardware_requirements": release_metadata['hardware_requirements'][:3] if release_metadata['hardware_requirements'] else [],  # Limit to first 3 requirements
                    "known_issues": release_metadata['known_issues'][:3] if release_metadata['known_issues'] else [],  # Limit to first 3 issues
                    "changelog": release_metadata['changelog'][:5] if release_metadata['changelog'] else []  # Limit to first 5 changelog items
                }
                
                builds.append(build)
                self.log(f"üì¶ Found: {bin_file.name} - {metadata['model']} {metadata['variant']} v{metadata['version']}")
        
        # Sort by model, then variant, then version
        builds.sort(key=lambda x: (x['model'], x['variant'], x['version']))
        return builds
    
    def create_main_manifest(self, builds: list) -> bool:
        """Create main manifest.json file."""
        try:
            manifest = {
                "name": "Sense360 ESP32 Firmware",
                "version": "1.0.0",
                "home_assistant_domain": "esphome",
                "new_install_skip_erase": False,
                "builds": builds
            }
            
            with open(self.manifest_path, 'w') as f:
                json.dump(manifest, f, indent=2)
            
            self.log(f"‚úì Created manifest.json with {len(builds)} builds")
            return True
            
        except Exception as e:
            self.log(f"ERROR: Failed to create manifest.json: {e}")
            return False
    
    def create_individual_manifests(self, builds: list) -> bool:
        """Create individual manifest files for ESP Web Tools."""
        try:
            for index, build in enumerate(builds):
                individual_manifest = {
                    "name": f"Sense360 ESP32 Firmware - {build['device_type']}",
                    "version": build['version'],
                    "home_assistant_domain": "esphome",
                    "new_install_skip_erase": False,
                    "builds": [{
                        "chipFamily": build['chipFamily'],
                        "parts": [{
                            "path": build['parts'][0]['path'],
                            "offset": 0
                        }],
                        "improv": True
                    }]
                }
                
                manifest_filename = f'firmware-{index}.json'
                with open(manifest_filename, 'w') as f:
                    json.dump(individual_manifest, f, indent=2)
                
                self.log(f"‚úì Created {manifest_filename} for {build['device_type']} v{build['version']}")
            
            return True
            
        except Exception as e:
            self.log(f"ERROR: Failed to create individual manifests: {e}")
            return False
    
    def validate_deployment(self, builds: list) -> bool:
        """Validate all files exist and are accessible."""
        try:
            # Check main manifest
            if not self.manifest_path.exists():
                self.log("ERROR: manifest.json not found")
                return False
            
            # Validate main manifest content
            with open(self.manifest_path) as f:
                manifest_data = json.load(f)
                
            if len(manifest_data['builds']) != len(builds):
                self.log(f"ERROR: Main manifest has {len(manifest_data['builds'])} builds but expected {len(builds)}")
                return False
            
            # Check individual manifests
            for index, build in enumerate(builds):
                manifest_file = Path(f'firmware-{index}.json')
                if not manifest_file.exists():
                    self.log(f"ERROR: Individual manifest {manifest_file} not found")
                    return False
                
                # Check firmware file exists
                firmware_path = Path(build['parts'][0]['path'])
                if not firmware_path.exists():
                    self.log(f"ERROR: Firmware file not found: {firmware_path}")
                    return False
            
            # Check for orphaned manifest files
            all_manifests = list(Path('.').glob('firmware-*.json'))
            expected_manifests = [Path(f'firmware-{i}.json') for i in range(len(builds))]
            
            orphaned_manifests = set(all_manifests) - set(expected_manifests)
            if orphaned_manifests:
                self.log(f"ERROR: Found {len(orphaned_manifests)} orphaned manifest files:")
                for orphaned in orphaned_manifests:
                    self.log(f"  - {orphaned}")
                return False
            
            # Verify perfect synchronization
            firmware_count = len(list(self.firmware_dir.rglob('*.bin')))
            manifest_count = len(all_manifests)
            build_count = len(builds)
            
            if firmware_count != manifest_count or firmware_count != build_count:
                self.log(f"ERROR: Synchronization mismatch - Firmware: {firmware_count}, Manifests: {manifest_count}, Builds: {build_count}")
                return False
            
            self.log("‚úì All deployment files validated")
            self.log(f"‚úì Perfect synchronization confirmed: {firmware_count} firmware = {manifest_count} manifests = {build_count} builds")
            return True
            
        except Exception as e:
            self.log(f"ERROR: Validation failed: {e}")
            return False
    
    def run_complete_automation(self) -> bool:
        """Run complete automation workflow with guaranteed clean state."""
        self.log("=" * 60)
        self.log("STARTING CLEAN STATE AUTOMATION")
        self.log("=" * 60)
        
        # Step 1: Pre-run cleanup - Remove ALL firmware-*.json files
        self.log("üßπ Step 1: Pre-run cleanup")
        if not self.clean_orphaned_manifests():
            self.log("‚ùå Pre-run cleanup failed")
            return False
        
        # Step 2: Scan firmware directory for actual .bin files
        self.log("üì¶ Step 2: Scanning firmware directory")
        builds = self.scan_firmware_directory()
        if not builds:
            self.log("‚ö†Ô∏è  No firmware files found. Please add .bin files to firmware/ directory.")
            return False
        
        # Step 3: Create main manifest based on actual files
        self.log("üìÑ Step 3: Creating main manifest")
        if not self.create_main_manifest(builds):
            self.log("‚ùå Main manifest creation failed")
            return False
        
        # Step 4: Create individual manifests for each firmware
        self.log("üìã Step 4: Creating individual manifests")
        if not self.create_individual_manifests(builds):
            self.log("‚ùå Individual manifest creation failed")
            return False
        
        # Step 5: Validate complete deployment
        self.log("‚úÖ Step 5: Validating deployment")
        if not self.validate_deployment(builds):
            self.log("‚ùå Deployment validation failed")
            return False
        
        # Success summary
        self.log("=" * 60)
        self.log("‚úÖ CLEAN STATE AUTOMATION COMPLETED")
        self.log("=" * 60)
        self.log(f"‚úì Cleaned up orphaned manifest files")
        self.log(f"‚úì {len(builds)} firmware builds processed with accurate dates")
        self.log(f"‚úì Main manifest.json created")
        self.log(f"‚úì {len(builds)} individual manifests created")
        self.log("‚úì All files use relative URLs for GitHub Pages")
        self.log("‚úì ESP Web Tools compatibility confirmed")
        self.log("‚úì Perfect synchronization between firmware/ directory and manifests")
        self.log("")
        self.log("CLEAN STATE GUARANTEE:")
        self.log("1. ‚úì All orphaned manifest files removed")
        self.log("2. ‚úì Manifests match exactly with existing .bin files")
        self.log("3. ‚úì Accurate build dates from git commits or file timestamps")
        self.log("4. ‚úì No manual editing required - 100% automated")
        self.log("5. ‚úì Ready for GitHub Pages deployment")
        self.log("")
        self.log("AUTOMATION WORKFLOW:")
        self.log("‚Ä¢ Add .bin file to firmware/ directory")
        self.log("‚Ä¢ Run: python3 deploy-automation.py")
        self.log("‚Ä¢ Commit and push to GitHub")
        self.log("‚Ä¢ GitHub Pages will serve updated firmware")
        self.log("=" * 60)
        
        return True

def main():
    parser = argparse.ArgumentParser(description='GitHub Pages deployment automation')
    parser.add_argument('--local', action='store_true', help='Use localhost URLs for development')
    parser.add_argument('--validate', action='store_true', help='Validate existing deployment')
    
    args = parser.parse_args()
    
    automation = GitHubPagesAutomation(local_mode=args.local)
    
    if args.validate:
        # For validation, we need to scan first
        builds = automation.scan_firmware_directory()
        if automation.validate_deployment(builds):
            print("‚úì Deployment validation passed")
            return 0
        else:
            print("‚úó Deployment validation failed")
            return 1
    else:
        if automation.run_complete_automation():
            print("‚úì Automation completed successfully")
            return 0
        else:
            print("‚úó Automation failed")
            return 1

if __name__ == '__main__':
    exit(main())